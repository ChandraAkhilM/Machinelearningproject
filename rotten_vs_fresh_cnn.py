# -*- coding: utf-8 -*-
"""Rotten_vs_Fresh_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mZOANFmOyWpgD5mdyBP9v0cgySiriUT1
"""

from google.colab import drive
drive.mount('/content/gdrive')

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os

# Commented out IPython magic to ensure Python compatibility.
# Importing libraries
import keras
import tensorflow as tf
import matplotlib.pyplot as plt
# %matplotlib inline
import os

# Getting labels of training data
labels = os.listdir("/content/gdrive/MyDrive/Rotten VS Fresh/train")
labels

"""# display images"""

# for displaying images
from IPython.display import display, Image

num = []

for i in labels:
  path = '/content/gdrive/MyDrive/Rotten VS Fresh/train{0}/'.format(i)
  folder_data = os.listdir(path)
  k=0
  print('\n', i.upper())
  for j in folder_data:
    if(k<2):
      display(Image(path+j))
    k=k+1
  num.append(k)
  print('there are ', k,' images in ', i, 'class')

from google.colab import drive
drive.mount('/content/drive')

# getting images from files using ImageDataGenerator

from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

tg = datagen.flow_from_directory(directory='/content/drive/MyDrive/Rotten VS Fresh/train', target_size=(20,20), classes=labels, batch_size=25, subset='training')
vg = datagen.flow_from_directory(directory='/content/drive/MyDrive/Rotten VS Fresh/test', target_size=(20,20), classes=labels, batch_size=25, subset='validation')

"""# **CNN Model**"""

# building model
model = tf.keras.Sequential()
model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape = (20,20,3)))
model.add(tf.keras.layers.MaxPool2D((2,2)))

model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))
model.add(tf.keras.layers.MaxPool2D((2,2)))

model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(128, activation='relu'))
model.add(tf.keras.layers.Dense(128, activation='relu'))

model.add(tf.keras.layers.Dense(6, activation='softmax'))

# compiling model
model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])

# runing model
history = model.fit_generator(generator=tg, steps_per_epoch=len(tg), epochs=8, validation_data=vg, validation_steps=len(vg))

"""# Learning Curves"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Acc','Val'], loc = 'upper left')

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['loss','Val'], loc = 'upper left')